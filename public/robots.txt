# robots.txt for https://aminah.ai

User-agent: *
Allow: /

# Disallow admin or private pages if any
# Disallow: /admin/
# Disallow: /private/

# Sitemap location
Sitemap: https://aminah.ai/sitemap.xml

# Crawl-delay (optional, adjust as needed)
Crawl-delay: 10

# Block specific bots if needed (example)
# User-agent: BadBot
# Disallow: /
